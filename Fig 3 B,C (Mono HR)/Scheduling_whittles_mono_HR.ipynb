{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e3f15839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random\n",
    "import copy\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f94a5e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise-\n",
    "action = np.zeros(9)\n",
    "state = np.zeros(9)\n",
    "Q = np.zeros((10,2,10,9))\n",
    "\n",
    "hist0 = []\n",
    "hist1 = []\n",
    "hist2 = []\n",
    "\n",
    "W = np.zeros((10,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "79a39f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(step,p1,lamda):\n",
    "    pi = [0]*step\n",
    "    for i in range(step):\n",
    "        pi[i]=(1-(1-p1)*((lamda)**i))\n",
    "    mul = pi[step-1]\n",
    "    return mul \n",
    "\n",
    "class envir():\n",
    "    def __init__(self):\n",
    "        self.phi = 9\n",
    "        self.lamda = 0.8 \n",
    "        self.p1=[]\n",
    "        for i in range(9):\n",
    "            self.p1.append(0.1*(i+1))\n",
    "\n",
    "    def step(self,s,task):\n",
    "            next_state = copy.copy(s)\n",
    "            if s[task] == 0:\n",
    "                next_state[task] = 0\n",
    "                #print('e')\n",
    "            else:\n",
    "                next_state[task] = random.choice([0,s[task]+1],1,p=[get_prob(s[task],self.p1[task],self.lamda),1-get_prob(s[task],self.p1[task],self.lamda)])\n",
    "                #print('ee')\n",
    "            #print(next_state)\n",
    "            if s[task]!=0 and next_state[task] == 0:\n",
    "                reward = 1\n",
    "            elif s[task]==0:\n",
    "                reward = -10000\n",
    "            else:\n",
    "                reward = 0\n",
    "            return next_state,reward\n",
    "\n",
    "def choose_arm(s,We,epsilon):\n",
    "    p = random.rand()\n",
    "    if p>epsilon:\n",
    "        k = []\n",
    "        for i in range(9):\n",
    "            k.append(We[s[i]][i])\n",
    "        max_index = np.argmax(k)  # Get the index of the maximum value\n",
    "        return max_index\n",
    "    else:\n",
    "        return random.randint(0,9)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5ba5facb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harshit\\AppData\\Local\\Temp\\ipykernel_39036\\3875976697.py:22: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  next_state[task] = random.choice([0,s[task]+1],1,p=[get_prob(s[task],self.p1[task],self.lamda),1-get_prob(s[task],self.p1[task],self.lamda)])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[216], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     a[task] \u001b[38;5;241m=\u001b[39m r\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mgame\u001b[39;00m():\n\u001b[0;32m     11\u001b[0m     gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.99\u001b[39m\n\u001b[0;32m     12\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.4\u001b[39m\n",
      "Cell \u001b[1;32mIn[216], line 45\u001b[0m, in \u001b[0;36mgame\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m9\u001b[39m):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m---> 45\u001b[0m         \u001b[43mQ\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m[k][i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\u001b[38;5;241m*\u001b[39m((\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39maction[i])\u001b[38;5;241m*\u001b[39m(reward[i]\u001b[38;5;241m+\u001b[39mW[k][i])\u001b[38;5;241m+\u001b[39maction[i]\u001b[38;5;241m*\u001b[39mreward[i]\u001b[38;5;241m+\u001b[39mgamma\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mmax\u001b[39m(Q[next_state[i]][\u001b[38;5;241m0\u001b[39m][k][i],Q[next_state[i]][\u001b[38;5;241m1\u001b[39m][k][i]))\u001b[38;5;241m-\u001b[39mQ[s[i]][action[i]][k][i])\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;66;03m#print(s[i].astype(int))\u001b[39;00m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;66;03m#print(s[i])\u001b[39;00m\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;66;03m#print(action[i].astype(int))\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m9\u001b[39m):\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "def get_action(task):\n",
    "    a = np.zeros((9))\n",
    "    a[task] = 1\n",
    "    return a\n",
    "def get_reward(task,r):\n",
    "    a = np.zeros((9))\n",
    "    a[task] = r\n",
    "    return a\n",
    "\n",
    "class game():\n",
    "    gamma = 0.99\n",
    "    epsilon = 0.4\n",
    "    s = np.array([1,1,1,1,1,1,1,1,1])\n",
    "    state = np.array([1,1,1,1,1,1,1,1,1])\n",
    "    episodes = 100\n",
    "    rate = 1\n",
    "    start_time = time.time()\n",
    "    t = []\n",
    "    hist = []\n",
    "    beta = 1\n",
    "    env = envir()\n",
    "    for episode_no in range(episodes):\n",
    "        s = np.array([1,1,1,1,1,1,1,1,1])\n",
    "        if episode_no==0:\n",
    "            learning_rate = 0.1\n",
    "        if episode_no>=1:\n",
    "            learning_rate = 1 / math.ceil(episode_no / 5000)\n",
    "            if(episode_no%10==0):\n",
    "                beta = 1 / (1 + math.ceil(episode_no * math.log(episode_no) / 5000))\n",
    "            else:\n",
    "                beta = 0\n",
    "        while (s[0]!=0 or s[1]!=0 or s[2]!=0 or s[3]!=0 or s[4]!=0 or s[5]!=0 or s[6]!=0 or s[7]!=0 or s[8]!=0):\n",
    "            task = choose_arm(s=state,We=W,epsilon=0.4)\n",
    "            action = get_action(task)\n",
    "            next_state,r = env.step(s,task)\n",
    "            reward = get_reward(task,r)\n",
    "            inde = 0\n",
    "            current_time = time.time()-start_time\n",
    "            hist.append(W[4][1])\n",
    "            t.append(current_time)\n",
    "            if episode_no%10==0:\n",
    "                rate = rate - 0.00002        \n",
    "            for i in range(9):\n",
    "                for k in range(10):\n",
    "                    Q[s[i].astype(int)][action[i].astype(int)][k][i] += 0.1*((1-action[i])*(reward[i]+W[k][i])+action[i]*reward[i]+gamma*(max(Q[next_state[i].astype(int)][0][k][i],Q[next_state[i].astype(int)][1][k][i]))-Q[s[i].astype(int)][action[i].astype(int)][k][i])\n",
    "                    #print(s[i].astype(int))\n",
    "                    #print(s[i])\n",
    "                    #print(action[i].astype(int))\n",
    "            for i in range(9):\n",
    "                for k in range(10):    \n",
    "                    W[k][i] += 0.05*(Q[k][1][k][i]-Q[k][0][k][i])\n",
    "            s = next_state\n",
    "    plt.title('Gittins index of state 4 of job 2 vs runtime plot',fontsize='xx-large')\n",
    "    plt.xlabel('Time', fontsize = 'xx-large')\n",
    "    plt.ylabel('Gittins index',fontsize = 'xx-large')\n",
    "    plt.plot(t,hist,'-',c='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "791a2fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.game at 0x206b21f9090>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633280bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c56ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
