{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f0fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random\n",
    "from mpmath import mp\n",
    "import time \n",
    "import copy \n",
    "import csv\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9355900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_with_counter(file_name):\n",
    "    row_counter = 0\n",
    "    rowwise_lists = []\n",
    "\n",
    "    # Open and read the CSV file\n",
    "    with open(file_name, mode='r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        headers = next(reader)  # Skip header row\n",
    "\n",
    "        # Iterate through each row in the CSV file\n",
    "        for row in reader:\n",
    "            row_as_int = [int(value) for value in row]  # Convert each value to integer\n",
    "            rowwise_lists.append(row_as_int)\n",
    "            row_counter += 1  # Increment the counter\n",
    "    return rowwise_lists\n",
    "\n",
    "file_name = \"C:\\Intern\\Gittin\\'s plots\\All codes directory\\Fig 3 A (Const HR)\\jobsizes_constHR.csv\"  # Replace with the actual file name\n",
    "rowwise_lists = load_csv_with_counter(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24781bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_v_values(Q_values_action1, Q_values_action2):\n",
    "    V_values = np.zeros((2,10))\n",
    "    for i in range(2):\n",
    "        for j in range(10):\n",
    "            V_values[i][j] = max(Q_values_action1[i][j],Q_values_action2[i][j])  # Use keepdims=True to maintain the 2D shape\n",
    "    return V_values\n",
    "\n",
    "V_true = np.array([[ 0,         0,          0,          0,          0,          0,\n",
    "   0,          0,          0,          0        ],\n",
    "   [5.20609088, 10.98257709, 16.18277733, 21.10806607, 26.14558744, 30.49934127,\n",
    "  36.64971727, 41.42251637, 45.25001465, 50.77376517]])\n",
    "# V_true = [9, 8.15241315, 7.47595723, 6.90163656, 6.49113047]\n",
    "\n",
    "def bellman_relative_error(V_approx, V_true):\n",
    "    nonzero_indices = V_true != 0\n",
    "    if np.any(nonzero_indices):\n",
    "        #relative_errors = np.abs((V_approx[nonzero_indices] - V_true[nonzero_indices]) / V_true[nonzero_indices])\n",
    "        relative_errors = np.abs((V_approx[nonzero_indices] - V_true[nonzero_indices]))\n",
    "        return np.mean(relative_errors)\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce9623ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(step,p1):\n",
    "    pi = [0]*step\n",
    "    for i in range(1,step):\n",
    "        pi[i]=(1-(1-p1)*((lamda)**(1/i)))\n",
    "    mul = pi[step-1]\n",
    "    return mul \n",
    "\n",
    "class envir():\n",
    "    def __init__(self):\n",
    "        self.phi = 9\n",
    "        self.p1=[]\n",
    "        for i in range(10):\n",
    "            self.p1.append(0.05*(i+1))\n",
    "    def step(self,s,state_dict,task,jobsize):\n",
    "            s_old = s[task]\n",
    "            reward = [0]*10\n",
    "            next_state = copy.copy(s)\n",
    "            if(state_dict[f\"{task}\"]==jobsize[task] or s_old==0):\n",
    "                s_new = 0\n",
    "            else:\n",
    "                state_dict[f\"{task}\"] += 1\n",
    "                s_new = s_old\n",
    "            next_state[task] = s_new\n",
    "            if s[task]!=0 and next_state[task] == 0:\n",
    "                reward[task] = 1\n",
    "            elif s[task]==0:\n",
    "                reward[task] = -10000\n",
    "            else:\n",
    "                reward[task] = 0\n",
    "            return next_state,state_dict,reward[task]\n",
    "    \n",
    "    def getjobsize(self, job_counter):\n",
    "        jobsize = rowwise_lists[job_counter]\n",
    "        return jobsize\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self,alpha,T,gamma):\n",
    "        self.Q_values = np.zeros((2,2,2,10))\n",
    "        self.phi = 9\n",
    "        self.alpha = alpha\n",
    "        self.T = T\n",
    "        self.gamma = gamma\n",
    "    def activate_task(self,s):\n",
    "        num = []\n",
    "        summ = 0\n",
    "        prob = []\n",
    "        for i in range(10):\n",
    "            num.append(mp.exp((self.Q_values[s[i]][0][s[i]][i])/self.T))\n",
    "            summ = summ + mp.exp((self.Q_values[s[i]][0][s[i]][i])/self.T)\n",
    "        for i in range(10):\n",
    "            prob.append(num[i]/summ)\n",
    "        task = random.choice(10,1,p=prob)\n",
    "        return task[0]\n",
    "    \n",
    "    def activate_task_eps_greedy(self,s,epsilon):\n",
    "            wl= []\n",
    "            p = np.array([0,0,0,0,0,0,0,0,0,0])\n",
    "            if np.random.random() < epsilon:\n",
    "                for i in range(len(p)):\n",
    "                    if s[i]!=0:\n",
    "                        wl.append(i)\n",
    "                arm_to_pull = np.random.choice(wl,1)[0]\n",
    "                p[arm_to_pull] = 1\n",
    "                return arm_to_pull\n",
    "            else:\n",
    "                p2 = {}\n",
    "                for i in range(len(p)):\n",
    "                    if s[i]!=0:\n",
    "                        p2[i] = self.Q_values[s[i]][0][s[i]][i]\n",
    "                max_key = max(p2, key=p2.get)\n",
    "                p[max_key] = 1\n",
    "                return max_key\n",
    "            \n",
    "    def check_best_action(self,state):\n",
    "        ind = 0\n",
    "        for i,_ in reversed(list(enumerate(state))):\n",
    "            if state[i] == 1:\n",
    "                ind = i\n",
    "                break\n",
    "        return ind\n",
    "    \n",
    "    def act_greedy(self,s,restart_prob,task):\n",
    "        return max((self.Q_values[s[task]][0][restart_prob][task]),(self.Q_values[s[task]][1][restart_prob][task]))\n",
    "    \n",
    "    def update(self,s,task,next_state,reward):\n",
    "        for k in range(2):\n",
    "            self.Q_values[s[task]][0][k][task] = (1-self.alpha)*(self.Q_values[s[task]][0][k][task]) + self.alpha*(reward+self.gamma*(self.act_greedy(next_state,k,task)))\n",
    "            self.Q_values[k][1][s[task]][task] = (1-self.alpha)*(self.Q_values[k][1][s[task]][task]) + self.alpha*(reward+self.gamma*(self.act_greedy(next_state,s[task],task)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9288fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1806/2500 [11:48<08:21,  1.38it/s]"
     ]
    }
   ],
   "source": [
    "class pull():\n",
    "        start_time = time.time()\n",
    "        env = envir()\n",
    "        hist01 = []\n",
    "        t = []\n",
    "        BRE = []\n",
    "        agent = Agent(alpha=0.1,T=1000,gamma=0.99)\n",
    "        episode = 2500\n",
    "        agent.alpha = 0.1\n",
    "        agent.gamma = 0.99\n",
    "        agent.T = 750000\n",
    "        Tmax = 750000\n",
    "        Tmin = 0.25\n",
    "        s = np.array([1,1,1,1,1,1,1,1,1,1])\n",
    "        phi = 3\n",
    "        cumm_rew = []\n",
    "        plt_wrong_actions = []\n",
    "        eps = 1\n",
    "        cumm_wrong_steps = []\n",
    "        for ep_no in tqdm(range(episode)):\n",
    "            s = np.array([1,1,1,1,1,1,1,1,1,1])\n",
    "            state_dict = {\"0\":1,\"1\":1,\"2\":1,\"3\":1,\"4\":1,\"5\":1,\"6\":1,\"7\":1,\"8\":1,\"9\":1}\n",
    "            episode_rew = 0 \n",
    "            eps = eps*0.9985\n",
    "            jobsize = env.getjobsize(ep_no)\n",
    "            while (s[0]!=0 or s[1]!=0 or s[2]!=0 or s[3]!=0 or s[4]!=0 or s[5]!=0 or s[6]!=0 or s[7]!=0 or s[8]!=0 or s[9]!=0):\n",
    "                #print(s)\n",
    "                task = agent.activate_task(s)\n",
    "                if len(cumm_rew)==0:\n",
    "                    cumm_rew.append(episode_rew)\n",
    "                else:\n",
    "                    cumm_rew.append(cumm_rew[-1]+episode_rew)\n",
    "                task_eps = agent.activate_task_eps_greedy(s,eps)\n",
    "                task = task_eps\n",
    "                task_opt = agent.check_best_action(s)\n",
    "                if task_eps != task_opt:\n",
    "                    cumm_wrong_steps.append(1)\n",
    "                else:\n",
    "                    cumm_wrong_steps.append(0)\n",
    "                plt_wrong_actions.append(np.mean(cumm_wrong_steps)*100)\n",
    "                Q0 = np.zeros((2,10))\n",
    "                M = np.zeros((2,10))\n",
    "                for i in range(2):\n",
    "                    for j in range(10):\n",
    "                        Q0[i][j] = agent.Q_values[i][0][i][j]\n",
    "                        M[i][j] = agent.Q_values[i][1][i][j]\n",
    "                V_values = calculate_v_values(Q0,M)\n",
    "                BRE.append(bellman_relative_error(V_values,V_true))\n",
    "                #print(task)\n",
    "                current_time = time.time()-start_time\n",
    "                next_state,state_dict,reward = env.step(copy.copy(s),state_dict,task,jobsize)\n",
    "                episode_rew+=reward\n",
    "                #print(next_state)\n",
    "                #print('r',reward)\n",
    "                agent.update(s,task,next_state,reward)\n",
    "                t.append(current_time)\n",
    "                if((ep_no%100)==0):\n",
    "                    agent.alpha = agent.alpha-0.000002\n",
    "                s = copy.copy(next_state)\n",
    "                hist01.append(0.01*agent.Q_values[1][0][1][5])\n",
    "        plt.title('Gittins index of state 1 of job 6 vs runtime plot',fontsize='xx-large')\n",
    "        plt.xlabel('Time', fontsize = 'xx-large')\n",
    "        plt.ylabel('Gittins index',fontsize = 'xx-large')\n",
    "        plt.plot(t,hist01,'-',c='red')\n",
    "        plt.show()\n",
    "\n",
    "        filename = 'C:\\\\Intern\\\\percent_wrong_restart_constHR.csv'\n",
    "\n",
    "        # Writing to CSV file\n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['percent_wrong'])  # Writing the header\n",
    "            for value in plt_wrong_actions:\n",
    "                writer.writerow([value])  # Writing each value in a new row\n",
    "\n",
    "        filename = 'C:\\\\Intern\\\\BRE_restart_constHR.csv'\n",
    "\n",
    "        # Writing to CSV file\n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['BRE'])  # Writing the header\n",
    "            for value in BRE:\n",
    "                writer.writerow([value])  # Writing each value in a new row\n",
    "\n",
    "        filename = 'C:\\\\Intern\\\\cumm_rew_restart_constHR.csv'\n",
    "\n",
    "        # Writing to CSV file\n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['cumm_rew'])  # Writing the header\n",
    "            for value in cumm_rew:\n",
    "                writer.writerow([value])  # Writing each value in a new row     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12efb1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62466c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ac5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dream11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
